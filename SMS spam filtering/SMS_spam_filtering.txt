(base) C:\Users\kaundanyachinmaya07>python
Python 3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)] :: Anaconda, Inc. on win32
Type "help", "copyright", "credits" or "license" for more information.

# First importing the required modules

>>> import numpy as np

# data processing, CSV file I/O (e.g. pd.read_csv)

>>> import pandas as pd
>>> import warnings
>>> warnings.filterwarnings('ignore')
>>>

# importing the dataset that is emails.csv file

>>> dataset = pd.read_csv('C:\\Users\kaundanyachinmaya07\Desktop\sms_spam_dataset.csv', encoding='latin-1')
>>> dataset.head()
     v1                                                 v2 Unnamed: 2 Unnamed: 3 Unnamed: 4
0   ham  Go until jurong point, crazy.. Available only ...        NaN        NaN        NaN
1   ham                      Ok lar... Joking wif u oni...        NaN        NaN        NaN
2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN        NaN        NaN
3   ham  U dun say so early hor... U c already then say...        NaN        NaN        NaN
4   ham  Nah I don't think he goes to usf, he lives aro...        NaN        NaN        NaN
>>>

# removing unwanted columns

>>> dataset = dataset.drop(["Unnamed: 2", "Unnamed: 3", "Unnamed: 4"], axis=1)
>>>

# renaming columns

>>> dataset = dataset.rename(columns={"v1":"label", "v2":"text"})
>>> dataset.head()
  label                                               text
0   ham  Go until jurong point, crazy.. Available only ...
1   ham                      Ok lar... Joking wif u oni...
2  spam  Free entry in 2 a wkly comp to win FA Cup fina...
3   ham  U dun say so early hor... U c already then say...
4   ham  Nah I don't think he goes to usf, he lives aro...
>>>

# count observations in each label

>>> dataset.label.value_counts()
ham     4825
spam     747
Name: label, dtype: int64
>>>

# convert label to a numerical variable

>>> dataset['numerical_label'] = dataset.label.map({'ham':0, 'spam':1})
>>> dataset.head()
  label                                               text  numerical_label
0   ham  Go until jurong point, crazy.. Available only ...                0
1   ham                      Ok lar... Joking wif u oni...                0
2  spam  Free entry in 2 a wkly comp to win FA Cup fina...                1
3   ham  U dun say so early hor... U c already then say...                0
4   ham  Nah I don't think he goes to usf, he lives aro...                0
>>>

# for splitting dataset into train set and test set

>>> from sklearn.model_selection import train_test_split
>>>
>>> X_train,X_test,y_train,y_test = train_test_split(dataset["text"],dataset["label"], test_size = 0.2, random_state = 10)
>>> print(X_train.shape)
(4457,)
>>> print(X_test.shape)
(1115,)
>>> print(y_train.shape)
(4457,)
>>> print(y_test.shape)
(1115,)
>>>

# for vectorizing words

>>> from sklearn.feature_extraction.text import CountVectorizer
>>>
>>> vect = CountVectorizer(stop_words='english')
>>> vect.fit(X_train)
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)
>>>
>>>
>>> print(vect.get_feature_names()[0:20])
['00', '000', '000pes', '008704050406', '0089', '0121', '01223585236', '01223585334', '0125698789', '02', '0207', '02072069400', '02073162414', '02085076972', '021', '03', '04', '0430', '05', '050703']
>>> print(vect.get_feature_names()[-20:])
['zyada', 'åð', 'åòharry', 'åòit', 'åômorrow', 'åôrents', 'ì_', 'ì¼1', 'ìä', 'ìï', 'ó_', 'û_', 'û_thanks', 'ûªm', 'ûªt', 'ûªve', 'ûï', 'ûïharry', 'ûò', 'ûówell']
>>>
>>> X_train_df = vect.transform(X_train)
>>> X_test_df = vect.transform(X_test)
>>> type(X_test_df)
<class 'scipy.sparse.csr.csr_matrix'>
>>>
>>> prediction = dict()

# Naive Bayes Machine Learning Model

>>> from sklearn.naive_bayes import MultinomialNB
>>> model = MultinomialNB()
>>> model.fit(X_train_df,y_train)
MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)
>>>
>>> prediction["naive_bayes"] = model.predict(X_test_df)
>>>
>>> from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
>>>

# get accuracy

>>> accuracy_score(y_test,prediction["naive_bayes"])
0.9883408071748879
>>>
>>> print(classification_report(y_test, prediction['naive_bayes'], target_names = ["Ham", "Spam"]))
             precision    recall  f1-score   support

        Ham       0.99      1.00      0.99       965
       Spam       0.97      0.94      0.96       150

avg / total       0.99      0.99      0.99      1115

>>>
>>> def classify(user_input):
...     custom_train = [('text', [user_input])]
...     custom_train = pd.DataFrame.from_items(custom_train)
...     text = custom_train.iloc[:, 0].values
...     return model.predict(vect.transform(text))
...
>>> text = input('Type here something and see if it belongs to spam: ')
Type here something and see if it belongs to spam: IMPORTANT - You could be entitled up to £3,160 in compensation from mis-sold PPI on a credit card or loan. Please reply PPI for info or STOP to opt out.
>>> print(classify(text))
['spam']
>>>
>>>
>>> text = input('Type here something and see if it belongs to spam: ')
Type here something and see if it belongs to spam: Hey there! I hope you're free tonight, let's catch up at dinner!
>>> print(classify(text))
['ham']
>>>
>>>